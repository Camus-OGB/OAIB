# Guide de Migration et D√©ploiement - Olympiades d'IA du B√©nin

## Table des mati√®res
1. [Strat√©gie de Migration](#migration)
2. [Gestion des Versions](#versions)
3. [Environnements](#environnements)
4. [D√©ploiement Cloud](#deploiement)
5. [Backup et Restauration](#backup)
6. [Monitoring](#monitoring)
7. [Optimisations](#optimisations)

---

## 1. Strat√©gie de Migration {#migration}

### Structure des fichiers de migration

```
migrations/
‚îú‚îÄ‚îÄ V1_0__initial_schema.sql
‚îú‚îÄ‚îÄ V1_1__add_gamification.sql
‚îú‚îÄ‚îÄ V1_2__add_audit_log.sql
‚îú‚îÄ‚îÄ V2_0__add_mobile_features.sql
‚îî‚îÄ‚îÄ rollback/
    ‚îú‚îÄ‚îÄ V1_1__rollback.sql
    ‚îú‚îÄ‚îÄ V1_2__rollback.sql
    ‚îî‚îÄ‚îÄ V2_0__rollback.sql
```

### Migration initiale (V1.0)

**V1_0__initial_schema.sql**
```sql
-- Cette migration contient le sch√©ma complet de base
-- (c'est le fichier olympiades_ia_schema.sql)
```

### Exemple de migration additionnelle (V1.1)

**V1_1__add_notifications_push.sql**
```sql
-- Migration V1.1 : Ajout des notifications push
-- Date : 2026-02-15
-- Auteur : √âquipe Dev

BEGIN;

-- Ajouter une table pour les tokens de notifications push
CREATE TABLE notification_tokens (
    id SERIAL PRIMARY KEY,
    utilisateur_id UUID REFERENCES utilisateurs(id) ON DELETE CASCADE,
    platform VARCHAR(20) CHECK (platform IN ('ios', 'android', 'web')),
    token TEXT NOT NULL,
    actif BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(utilisateur_id, platform, token)
);

-- Index pour performances
CREATE INDEX idx_notification_tokens_user ON notification_tokens(utilisateur_id);
CREATE INDEX idx_notification_tokens_actif ON notification_tokens(actif);

-- Ajouter une colonne pour tracer les notifications push envoy√©es
ALTER TABLE notifications 
ADD COLUMN push_envoye BOOLEAN DEFAULT FALSE,
ADD COLUMN push_envoye_at TIMESTAMP;

-- Commentaire
COMMENT ON TABLE notification_tokens IS 'Tokens FCM/APNs pour notifications push';

-- Insertion dans le log de migration
INSERT INTO schema_migrations (version, description, applied_at)
VALUES ('1.1', 'Ajout notifications push', NOW());

COMMIT;
```

**Rollback correspondant (V1_1__rollback.sql)**
```sql
BEGIN;

DROP TABLE IF EXISTS notification_tokens;

ALTER TABLE notifications 
DROP COLUMN IF EXISTS push_envoye,
DROP COLUMN IF EXISTS push_envoye_at;

DELETE FROM schema_migrations WHERE version = '1.1';

COMMIT;
```

### Table de suivi des migrations

```sql
-- √Ä cr√©er avant toute migration
CREATE TABLE schema_migrations (
    id SERIAL PRIMARY KEY,
    version VARCHAR(10) UNIQUE NOT NULL,
    description TEXT,
    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    applied_by VARCHAR(100) DEFAULT CURRENT_USER
);
```

### Script d'application de migrations

**migrate.sh**
```bash
#!/bin/bash

# Configuration
DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="olympiades_ia"
DB_USER="olympiades_user"
MIGRATIONS_DIR="./migrations"

# Couleurs pour les logs
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${GREEN}=== Olympiades IA - Migration Database ===${NC}"

# V√©rifier la connexion
psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "SELECT 1" > /dev/null 2>&1
if [ $? -ne 0 ]; then
    echo -e "${RED}‚ùå Impossible de se connecter √† la base de donn√©es${NC}"
    exit 1
fi

# Cr√©er la table de migrations si elle n'existe pas
psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
CREATE TABLE IF NOT EXISTS schema_migrations (
    id SERIAL PRIMARY KEY,
    version VARCHAR(10) UNIQUE NOT NULL,
    description TEXT,
    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    applied_by VARCHAR(100) DEFAULT CURRENT_USER
);" > /dev/null 2>&1

# Lister les migrations disponibles
MIGRATIONS=($(ls $MIGRATIONS_DIR/V*.sql | sort -V))

echo "Migrations disponibles : ${#MIGRATIONS[@]}"

# Appliquer chaque migration
for migration in "${MIGRATIONS[@]}"; do
    VERSION=$(basename "$migration" | sed 's/V\(.*\)__.*/\1/')
    DESCRIPTION=$(basename "$migration" | sed 's/V.*__\(.*\)\.sql/\1/' | tr '_' ' ')
    
    # V√©rifier si d√©j√† appliqu√©e
    ALREADY_APPLIED=$(psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "
        SELECT COUNT(*) FROM schema_migrations WHERE version = '$VERSION';
    " | tr -d ' ')
    
    if [ "$ALREADY_APPLIED" -gt 0 ]; then
        echo -e "${YELLOW}‚è≠Ô∏è  Migration v$VERSION d√©j√† appliqu√©e${NC}"
        continue
    fi
    
    echo -e "${GREEN}üì¶ Application de la migration v$VERSION...${NC}"
    
    # Appliquer la migration
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -f "$migration"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}‚úÖ Migration v$VERSION appliqu√©e avec succ√®s${NC}"
    else
        echo -e "${RED}‚ùå Erreur lors de l'application de la migration v$VERSION${NC}"
        exit 1
    fi
done

echo -e "${GREEN}=== Toutes les migrations ont √©t√© appliqu√©es ===${NC}"
```

**Rendre le script ex√©cutable :**
```bash
chmod +x migrate.sh
```

**Ex√©cuter les migrations :**
```bash
./migrate.sh
```

---

## 2. Gestion des Versions {#versions}

### Semantic Versioning

**Format : MAJOR.MINOR.PATCH**

- **MAJOR** : Changements incompatibles (breaking changes)
- **MINOR** : Nouvelles fonctionnalit√©s (r√©trocompatibles)
- **PATCH** : Corrections de bugs

**Exemples :**
- `1.0.0` : Version initiale en production
- `1.1.0` : Ajout des notifications push
- `1.1.1` : Correction d'un bug dans les notifications
- `2.0.0` : Refonte majeure de la structure QCM

### Changelog

**CHANGELOG.md**
```markdown
# Changelog - Base de donn√©es Olympiades IA

## [1.2.0] - 2026-03-01
### Ajout√©
- Table `application_mobile_stats` pour tracking analytics mobile
- Colonne `derniere_sync` dans table `candidats`

### Modifi√©
- Index optimis√©s sur table `sessions_qcm`
- Trigger `calculer_score_qcm` am√©lior√© pour performances

### Corrig√©
- Bug dans calcul du classement r√©gional quand √©galit√© de scores

## [1.1.0] - 2026-02-15
### Ajout√©
- Syst√®me de notifications push
- Table `notification_tokens`

## [1.0.0] - 2026-01-20
### Ajout√©
- Sch√©ma initial complet
- Toutes les tables de base
- Triggers automatiques
- Vues pour dashboards
```

---

## 3. Environnements {#environnements}

### Configuration par environnement

**config/database.dev.js**
```javascript
module.exports = {
  host: 'localhost',
  port: 5432,
  database: 'olympiades_ia_dev',
  username: 'dev_user',
  password: 'dev_password',
  logging: console.log, // Logs SQL activ√©s
  pool: {
    max: 5,
    min: 1
  }
};
```

**config/database.staging.js**
```javascript
module.exports = {
  host: process.env.DB_HOST,
  port: 5432,
  database: 'olympiades_ia_staging',
  username: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  logging: false,
  ssl: {
    rejectUnauthorized: false
  },
  pool: {
    max: 20,
    min: 5
  }
};
```

**config/database.prod.js**
```javascript
module.exports = {
  host: process.env.DB_HOST,
  port: 5432,
  database: 'olympiades_ia_prod',
  username: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  logging: false,
  ssl: {
    rejectUnauthorized: true,
    ca: fs.readFileSync('/path/to/ca-certificate.crt').toString()
  },
  pool: {
    max: 50,
    min: 10,
    acquire: 30000,
    idle: 10000
  }
};
```

### Donn√©es de test (seeding)

**seeds/01-roles.sql**
```sql
INSERT INTO roles (nom, description) VALUES 
    ('candidat', '√âl√®ve participant aux olympiades'),
    ('administrateur', 'Gestionnaire de la plateforme'),
    ('super_admin', 'Administrateur principal')
ON CONFLICT (nom) DO NOTHING;
```

**seeds/02-etablissements.sql**
```sql
INSERT INTO etablissements (nom, type, ville, departement, region) VALUES
    ('CEG Gbegamey', 'CEG', 'Cotonou', 'Littoral', 'Littoral'),
    ('Lyc√©e Mathieu Bouk√©', 'Lyc√©e', 'Parakou', 'Borgou', 'Borgou'),
    ('Coll√®ge CEG Dantokpa', 'CEG', 'Cotonou', 'Littoral', 'Littoral'),
    ('Lyc√©e Technique Coulibaly', 'Lyc√©e', 'Cotonou', 'Littoral', 'Littoral'),
    ('CEG Abomey-Calavi', 'CEG', 'Abomey-Calavi', 'Atlantique', 'Atlantique')
ON CONFLICT (nom, ville) DO NOTHING;
```

**seeds/03-badges.sql**
```sql
-- D√©j√† dans le sch√©ma principal via INSERT
```

**seeds/04-questions-test.sql**
```sql
-- Questions de test pour le QCM
INSERT INTO questions (categorie_id, enonce, type_question, niveau_difficulte, options, reponse_correcte, statut)
VALUES
    (1, 'Si tous les A sont des B, et tous les B sont des C, alors tous les A sont des C. Cette affirmation est :', 'qcm', 2, 
     '[{"lettre":"A","texte":"Vraie"},{"lettre":"B","texte":"Fausse"},{"lettre":"C","texte":"Impossible √† d√©terminer"}]'::jsonb,
     'A', 'active'),
    
    (1, 'Quelle est la prochaine lettre de la suite : A, C, F, J, ?', 'qcm', 3,
     '[{"lettre":"A","texte":"M"},{"lettre":"B","texte":"N"},{"lettre":"C","texte":"O"},{"lettre":"D","texte":"P"}]'::jsonb,
     'C', 'active'),
    
    (2, 'Si 5 ouvriers construisent un mur en 10 jours, combien de jours faudra-t-il √† 10 ouvriers pour construire le m√™me mur ?', 'qcm', 2,
     '[{"lettre":"A","texte":"5 jours"},{"lettre":"B","texte":"20 jours"},{"lettre":"C","texte":"10 jours"},{"lettre":"D","texte":"15 jours"}]'::jsonb,
     'A', 'active');
```

**Script de seeding**
```bash
#!/bin/bash
# seed.sh

DB_URL="postgresql://olympiades_user:password@localhost:5432/olympiades_ia_dev"

echo "üå± Seeding de la base de donn√©es..."

for seed_file in seeds/*.sql; do
    echo "üìù Application de $(basename $seed_file)"
    psql $DB_URL -f $seed_file
done

echo "‚úÖ Seeding termin√©"
```

---

## 4. D√©ploiement Cloud {#deploiement}

### Option 1 : AWS RDS (PostgreSQL)

**1. Cr√©ation de l'instance RDS**
```bash
aws rds create-db-instance \
    --db-instance-identifier olympiades-ia-prod \
    --db-instance-class db.t3.medium \
    --engine postgres \
    --engine-version 14.7 \
    --master-username admin_olympiades \
    --master-user-password <STRONG_PASSWORD> \
    --allocated-storage 100 \
    --storage-type gp3 \
    --storage-encrypted \
    --vpc-security-group-ids sg-xxxxxxxx \
    --db-subnet-group-name olympiades-subnet-group \
    --backup-retention-period 7 \
    --preferred-backup-window "03:00-04:00" \
    --preferred-maintenance-window "mon:04:00-mon:05:00" \
    --multi-az \
    --publicly-accessible false
```

**2. Configuration du groupe de s√©curit√©**
```bash
# Autoriser uniquement les serveurs d'application √† se connecter
aws ec2 authorize-security-group-ingress \
    --group-id sg-xxxxxxxx \
    --protocol tcp \
    --port 5432 \
    --source-group sg-app-servers
```

**3. Connection string**
```
postgresql://admin_olympiades:<PASSWORD>@olympiades-ia-prod.xxxxxxxxx.eu-west-1.rds.amazonaws.com:5432/olympiades_ia
```

### Option 2 : Google Cloud SQL

**1. Cr√©ation de l'instance**
```bash
gcloud sql instances create olympiades-ia-prod \
    --database-version=POSTGRES_14 \
    --tier=db-custom-4-16384 \
    --region=europe-west1 \
    --backup-start-time=03:00 \
    --enable-bin-log \
    --maintenance-window-day=MON \
    --maintenance-window-hour=4
```

**2. Cr√©ation de la base de donn√©es**
```bash
gcloud sql databases create olympiades_ia \
    --instance=olympiades-ia-prod
```

**3. Cr√©ation de l'utilisateur**
```bash
gcloud sql users create olympiades_user \
    --instance=olympiades-ia-prod \
    --password=<STRONG_PASSWORD>
```

### Option 3 : H√©bergement VPS (DigitalOcean, OVH)

**Installation PostgreSQL sur Ubuntu 22.04**
```bash
# Mise √† jour du syst√®me
sudo apt update && sudo apt upgrade -y

# Installation de PostgreSQL 14
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
sudo apt update
sudo apt install postgresql-14 postgresql-contrib-14 -y

# S√©curisation
sudo -u postgres psql -c "ALTER USER postgres PASSWORD '<STRONG_PASSWORD>';"

# Configuration pour accepter les connexions externes (si besoin)
sudo nano /etc/postgresql/14/main/postgresql.conf
# Modifier : listen_addresses = '*'

sudo nano /etc/postgresql/14/main/pg_hba.conf
# Ajouter : host all all 0.0.0.0/0 md5

# Red√©marrage
sudo systemctl restart postgresql
```

**Firewall**
```bash
# N'autoriser que les serveurs d'application
sudo ufw allow from <IP_APP_SERVER> to any port 5432
sudo ufw enable
```

### Configuration SSL/TLS

**G√©n√©rer un certificat auto-sign√© (dev/staging)**
```bash
sudo openssl req -new -x509 -days 365 -nodes -text \
    -out /etc/postgresql/14/main/server.crt \
    -keyout /etc/postgresql/14/main/server.key \
    -subj "/CN=olympiades-ia.local"

sudo chown postgres:postgres /etc/postgresql/14/main/server.{crt,key}
sudo chmod 600 /etc/postgresql/14/main/server.key
```

**postgresql.conf**
```conf
ssl = on
ssl_cert_file = '/etc/postgresql/14/main/server.crt'
ssl_key_file = '/etc/postgresql/14/main/server.key'
```

---

## 5. Backup et Restauration {#backup}

### Strat√©gie de backup

**Backup automatique quotidien**

**backup.sh**
```bash
#!/bin/bash

# Configuration
BACKUP_DIR="/var/backups/postgresql"
DB_NAME="olympiades_ia"
DB_USER="olympiades_user"
RETENTION_DAYS=30
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/${DB_NAME}_${DATE}.sql.gz"

# Cr√©er le r√©pertoire si inexistant
mkdir -p $BACKUP_DIR

# Backup
echo "üîÑ D√©marrage du backup de $DB_NAME..."

pg_dump -U $DB_USER -h localhost $DB_NAME | gzip > $BACKUP_FILE

if [ $? -eq 0 ]; then
    echo "‚úÖ Backup r√©ussi : $BACKUP_FILE"
    
    # Taille du backup
    SIZE=$(du -h $BACKUP_FILE | cut -f1)
    echo "üì¶ Taille : $SIZE"
    
    # Supprimer les backups de plus de X jours
    find $BACKUP_DIR -name "${DB_NAME}_*.sql.gz" -mtime +$RETENTION_DAYS -delete
    echo "üßπ Anciens backups nettoy√©s (>$RETENTION_DAYS jours)"
else
    echo "‚ùå √âchec du backup"
    exit 1
fi

# Upload vers S3 (optionnel)
if command -v aws &> /dev/null; then
    aws s3 cp $BACKUP_FILE s3://olympiades-ia-backups/postgresql/
    echo "‚òÅÔ∏è  Backup upload√© vers S3"
fi
```

**Automatisation avec cron**
```bash
# √âditer crontab
crontab -e

# Ajouter (backup quotidien √† 3h du matin)
0 3 * * * /path/to/backup.sh >> /var/log/postgresql_backup.log 2>&1
```

### Restauration

**Restaurer depuis un backup**
```bash
#!/bin/bash
# restore.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: ./restore.sh <backup_file.sql.gz>"
    exit 1
fi

DB_NAME="olympiades_ia"
DB_USER="olympiades_user"

echo "‚ö†Ô∏è  ATTENTION : Cette op√©ration va √©craser la base de donn√©es actuelle !"
read -p "√ätes-vous s√ªr ? (oui/non) : " CONFIRM

if [ "$CONFIRM" != "oui" ]; then
    echo "‚ùå Restauration annul√©e"
    exit 0
fi

echo "üîÑ Restauration en cours..."

# D√©compresser et restaurer
gunzip -c $BACKUP_FILE | psql -U $DB_USER -h localhost $DB_NAME

if [ $? -eq 0 ]; then
    echo "‚úÖ Restauration r√©ussie"
else
    echo "‚ùå √âchec de la restauration"
    exit 1
fi
```

### Backup incr√©mental avec WAL

**Configuration dans postgresql.conf**
```conf
wal_level = replica
archive_mode = on
archive_command = 'test ! -f /var/lib/postgresql/archive/%f && cp %p /var/lib/postgresql/archive/%f'
max_wal_senders = 3
```

---

## 6. Monitoring {#monitoring}

### M√©triques √† surveiller

**1. Performances de la base**
```sql
-- Requ√™tes lentes (> 1 seconde)
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    max_time
FROM pg_stat_statements
WHERE mean_time > 1000
ORDER BY total_time DESC
LIMIT 20;
```

**2. Taille des tables**
```sql
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
    pg_total_relation_size(schemaname||'.'||tablename) AS size_bytes
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY size_bytes DESC;
```

**3. Connexions actives**
```sql
SELECT 
    datname,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    state_change
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY query_start;
```

**4. Index non utilis√©s**
```sql
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0
ORDER BY schemaname, tablename;
```

### Script de monitoring

**monitor.sh**
```bash
#!/bin/bash

DB_NAME="olympiades_ia"
DB_USER="olympiades_user"
ALERT_EMAIL="admin@olympiades-ia-benin.org"

# V√©rifier la connexion
psql -U $DB_USER -d $DB_NAME -c "SELECT 1" > /dev/null 2>&1
if [ $? -ne 0 ]; then
    echo "‚ùå ALERTE : Impossible de se connecter √† la base" | mail -s "ALERTE DB" $ALERT_EMAIL
    exit 1
fi

# V√©rifier l'espace disque
DISK_USAGE=$(df -h /var/lib/postgresql | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 80 ]; then
    echo "‚ö†Ô∏è  ALERTE : Espace disque √† ${DISK_USAGE}%" | mail -s "ALERTE Espace Disque" $ALERT_EMAIL
fi

# V√©rifier le nombre de connexions
CONNECTIONS=$(psql -U $DB_USER -d $DB_NAME -t -c "SELECT count(*) FROM pg_stat_activity;")
if [ $CONNECTIONS -gt 80 ]; then
    echo "‚ö†Ô∏è  ALERTE : $CONNECTIONS connexions actives" | mail -s "ALERTE Connexions" $ALERT_EMAIL
fi

echo "‚úÖ Monitoring OK - $(date)"
```

### Dashboards avec Grafana + Prometheus

**Installation de postgres_exporter**
```bash
# T√©l√©charger
wget https://github.com/prometheus-community/postgres_exporter/releases/download/v0.11.1/postgres_exporter-0.11.1.linux-amd64.tar.gz
tar xvfz postgres_exporter-*.tar.gz
cd postgres_exporter-*/

# Configuration
export DATA_SOURCE_NAME="postgresql://olympiades_user:password@localhost:5432/olympiades_ia?sslmode=disable"

# Lancer
./postgres_exporter &
```

**prometheus.yml**
```yaml
scrape_configs:
  - job_name: 'postgresql'
    static_configs:
      - targets: ['localhost:9187']
```

---

## 7. Optimisations {#optimisations}

### Param√®tres PostgreSQL recommand√©s

**postgresql.conf (pour serveur 8GB RAM)**
```conf
# M√©moire
shared_buffers = 2GB
effective_cache_size = 6GB
maintenance_work_mem = 512MB
work_mem = 32MB

# Checkpoint
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100

# Parall√©lisation
max_worker_processes = 4
max_parallel_workers_per_gather = 2
max_parallel_workers = 4

# Planner
random_page_cost = 1.1  # Si SSD
effective_io_concurrency = 200

# Logging
log_min_duration_statement = 1000  # Log requ√™tes > 1s
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
```

### VACUUM et ANALYZE

**Configuration auto-vacuum**
```conf
autovacuum = on
autovacuum_max_workers = 3
autovacuum_naptime = 1min
autovacuum_vacuum_threshold = 50
autovacuum_analyze_threshold = 50
```

**VACUUM manuel hebdomadaire**
```bash
#!/bin/bash
# vacuum.sh

psql -U olympiades_user -d olympiades_ia <<EOF
VACUUM VERBOSE ANALYZE candidats;
VACUUM VERBOSE ANALYZE sessions_qcm;
VACUUM VERBOSE ANALYZE sessions_questions;
VACUUM VERBOSE ANALYZE evaluations_phases;
VACUUM VERBOSE ANALYZE notifications;
REINDEX DATABASE olympiades_ia;
EOF
```

### Partitionnement (pour grandes tables)

**Exemple : Partitionner audit_log par mois**
```sql
-- Convertir la table en table partitionn√©e
BEGIN;

-- Renommer la table existante
ALTER TABLE audit_log RENAME TO audit_log_old;

-- Cr√©er la table partitionn√©e
CREATE TABLE audit_log (
    id SERIAL,
    utilisateur_id UUID,
    action VARCHAR(100) NOT NULL,
    table_affectee VARCHAR(100),
    enregistrement_id VARCHAR(100),
    anciennes_valeurs JSONB,
    nouvelles_valeurs JSONB,
    adresse_ip INET,
    user_agent TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (created_at);

-- Cr√©er les partitions par mois
CREATE TABLE audit_log_2026_01 PARTITION OF audit_log
    FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

CREATE TABLE audit_log_2026_02 PARTITION OF audit_log
    FOR VALUES FROM ('2026-02-01') TO ('2026-03-01');

-- ... cr√©er les autres mois

-- Migrer les donn√©es
INSERT INTO audit_log SELECT * FROM audit_log_old;

-- Supprimer l'ancienne table
DROP TABLE audit_log_old;

COMMIT;
```

### Cache avec Redis

**Exemples de donn√©es √† cacher**
```javascript
const redis = require('redis');
const client = redis.createClient();

// Cacher le classement national (expire apr√®s 1 heure)
async function getClassementNational() {
  const cacheKey = 'classement:national';
  
  // Essayer le cache
  const cached = await client.get(cacheKey);
  if (cached) {
    return JSON.parse(cached);
  }
  
  // Sinon, requ√™te DB
  const classement = await sequelize.query(`
    SELECT * FROM vue_classement_national
    LIMIT 100
  `, { type: sequelize.QueryTypes.SELECT });
  
  // Mettre en cache
  await client.setEx(cacheKey, 3600, JSON.stringify(classement));
  
  return classement;
}
```

---

## Checklist de D√©ploiement

### Avant le d√©ploiement

- [ ] Tests de migration sur environnement de staging
- [ ] Backup complet de la base de production
- [ ] Tests de performance effectu√©s
- [ ] Documentation √† jour
- [ ] Scripts de rollback pr√©par√©s
- [ ] √âquipe pr√©venue de la maintenance

### Pendant le d√©ploiement

- [ ] Mettre le site en mode maintenance
- [ ] Arr√™ter les workers et jobs
- [ ] Backup de s√©curit√©
- [ ] Appliquer les migrations
- [ ] V√©rifier l'int√©grit√© des donn√©es
- [ ] Tests de fum√©e (smoke tests)
- [ ] Relancer les services

### Apr√®s le d√©ploiement

- [ ] Monitoring actif pendant 24h
- [ ] V√©rifier les logs d'erreurs
- [ ] Tester les fonctionnalit√©s critiques
- [ ] Communiquer la fin de maintenance
- [ ] Post-mortem si probl√®mes

---

## Conclusion

Ce guide couvre :
- ‚úÖ Strat√©gie de migration robuste
- ‚úÖ Gestion des environnements
- ‚úÖ D√©ploiement sur diff√©rents clouds
- ‚úÖ Backup et restauration
- ‚úÖ Monitoring et optimisations

La base de donn√©es est maintenant pr√™te pour un d√©ploiement en production s√©curis√© et performant !
